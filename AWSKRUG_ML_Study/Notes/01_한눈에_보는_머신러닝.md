# 1. 한눈에 보는 머신러닝

<br>

<br>

## 1.1 머신러닝이란?

<br>

### 머신러닝

> Data에서부터 학습하도록 컴퓨터를 프로그래밍하는 과학 (또는 예술)

<br>

#### 일반적 정의

: 명시적인 프로그래밍 없이 컴퓨터가 학습하는 능력을 갖추게 하는 연구분야		- Arthur Samule, 1959

<br>

#### 공학적 정의

: 어떤 작업 T에 대한 컴퓨터 프로그램의 성능을 P로 측정했을 때 경험 E로 인해 성능이 향상됐다면, 이 컴퓨터 프로그램은 작업 T와 성능 측정 P에 대해 경험 E로 학습한 것이다.		- Tom Mitchell, 1997

<br>

- `T (작업)`

  : 새로운 메일이 스팸인지 구분하는 것

- `E (경험)`

  : 훈련 데이터 (스팸 메일이 포함된 메일 데이터)

- `P (성능 측정)`

  : 정확도 (accuracy)

<br>

### 훈련 세트 (Training Set)

: System이 학습하는 데 사용하는 샘플

<br>

### 훈련 사례 (training instance) 또는 샘플

: 각 훈련 data

<br>

<br>

## 1.2 왜 머신러닝을 사용하는가?

 <br>

![](../../images/why-machine-learning_01.png)

<div align="center">[ 전통적인 접근 방법 ]</div>

<br>

![](../../images/why-machine-learning_02.png)

<div align="center">[ 머신러닝 접근 방법 ]</div>

<br>

![](../../images/why-machine-learning_03.png)

<div align="center">[ 자동으로 변화에 적응하는 머신러닝 ]</div>

<br>

![](../../images/why-machine-learning_04.png)

<div align="center">[ 머신러닝을 통해 배울 수 있다 ]</div>

<br>

### Data mining

: 머신러닝 기술을 적용하여 대용량의 데이터를 분석하여 보이지 않던 패턴을 발견하는 것

<br>

### 머신 러닝은 다음과 같은 분야에 뛰어나다

1. 기존 solution으로는 많은 수동 조정과 규칙이 필요한 문제
   - 하나의 머신러닝 모델이 코드를 간단하게 만들고, 전통적인 방법보다 더 잘 수행되도록 할 수 있다
2. 전통적인 방식으로는 해결 방법이 없는 복잡한 문제
3. 유동적인 환경
   - 머신러닝 시스템은 새로운 데이터에 적응할 수 있다
4. 복잡한 문제와 대략의 데이터에서 통찰 얻기

<br>

<br>

## 1.3 애플리케이션 사례

> 내가 관심 있는 것 몇 가지만 정리!

<br>

- #### 생산 라인에서 제품 이미지를 분석해 자동으로 분류하기

  - 이미지 분류 작업
  - `합성공 신경망 (CNN: Convolution Neural Network)`

- #### Chatbot 또는 개인 비서 만들기

  - `자연어 이해 (NLU: Natural Language Understanding)`
  - `질문 - 대답 모듈 (Question-answering module)`
  - 등 여러가지 `NLP (Natural Language Processing) 컴포넌트`가 필요함

- #### 다양한 성능 지표를 기반으로 회사의 내년도 수익을 예측하기

  - `회귀 (regression)` 작업
    - 숫자로 값을 예측
  - `선형 회귀 (linear regression)`
  - `다항 회귀 (polynomial regression)`
  - `회귀 SVM (Support Vector Machine)`
  - `회귀 랜덤 포레스트 (random forest)`
  - `인공 신경망 (Artificial Neural Network)`
  - 등 회귀 모델을 사용하여 해결

- #### 음성 명령에 반응하는 앱 만들기

  - 음성 인식 작업
  - 오디오 샘플 처리
  - `순환 신경망 (RNN: Recurrent Neural Network)`
  - `합성곱 신경망 (CNN: Convolutional Neural Network)`
  - `Transformer` 사용

- #### 구매 이력을 기반으로 고객을 나누고 각 집합마다 다른 마케팅 전략을 계획하기

  - `군집 (clustering) ` 작업

- #### 과거 구매 이력을 기반으로 고객이 관심을 가질 수 있는 상품 추천하기

  - 추천 시스템
  - 과거 구매이력을 `인공 신경망 (Artificial Neural Network)` 에 주입하고 다음에 구매할 가능성이 가장 높은 상품을 출력하는 것이 한 가지 방법
  - 일반적으로 모든 고객의 구매 이력을 기반으로 훈련

<br><br>

## 1.4 머신러닝 시스템의 종류

<br>

#### 머신러닝 시스템의 종류는 굉장히 많으므로 넓은 범주에서 분류하면 도움이 됨!

- 사람의 감독하에 훈련 or not
  - `지도 학습 (Supervised Learning)`
  - `비지도 학습 (Unsupervised Learning)`
  - `준지도 학습 (Semisupervised Learning)`
  - `강화 학습 (Reinforcement Learning)`
- 실시간으로 점진적인 학습 or not
  - `온라인 학습`
  - `배치 학습`
- 단순하게 알고 있는 데이터 포인트와 새 데이터 포인트를 비교 or 과학자들이 하는 것처럼 훈련 데이터셋에서 패턴을 발견하여 예측 모델을 만드는지
  - `사례 기반 학습`
  - `모델 기반 학습`

<br>

<br>

### 1.4.1 지도 학습과 비지도 학습

> 학습하는 동안의 감독 형태나 정보량에 따른 분류

<br>

#### 지도 학습 (Supervised learning)

: 지도 학습에는 알고리즘에 주입하는 훈련 데이터에 **레이블 (label)** 이라는 원하는 답이 포함됨

![](../../images/supervised-learning.png)

<div align="center">
    [ Spam 분류를 위한 Label 된 훈련 세트 (지도 학습의 예) ]
</div>

<br>

- **분류 (classification)** 가 전형적인 지도 학습 작업임
- **예측 변수 (predictor variable)** 라 부르는 **특성 (feature)** 을 사용해 중고차 가격 같은 **타깃 (Target)** 수치를 예측하는 것도 전형적인 지도 학습 작업
  - 이런 종류의 작업을 `회귀 (regression)` 이라고 부름

![](../../images/regression.png)

<div align="center"> [  Regression - 주어진 입력 특성으로 값을 예측 ] </div>

<br>

**지도 학습 알고리즘들**

- `k-최근접 이웃 (k-nearest neightbors)`
- `선형 회귀  (linear regression)`
- `로지스틱 회귀 (logistic regression)`
- `서포트 벡터 머신 (SVM: Support Vector Machine)`
- `결정 트리 (decision tree)` 와 `랜덤 포레스트 (random forest)`
- `신경망 (neural networks)`

<br>

<br>

#### 비지도 학습 (Unsupervised Learning)

: 말 그대로 훈련 데이터에 레이블이 없음. 시스템이 아무런 도움 없이 학습해야 함!

<br>

**비지도 학습 알고리즘들**

- `군집 (clustering)`

  ![](../../images/clustering.png)

  - **계층 군집 (hierarchical clustering)** 알고리즘을 사용하면 각 그룹을 더 작은 그룹으로 세분화 할 수 있음

  <br>

- `시각화 (visualization)` 와 `차원 축소 (dimensionality reduction)`

  - **시각화 알고리즘**
    - 레이블이 없는 대규모의 고차원 데이터를 넣으면 도식화가 가능한 2D나 3D 표현을 만들어줌
  - **차원 축소**
    - 너무 많은 작업을 잃지 않으면서 데이터를 간소화 하는 것
      - 상관 관계가 있는 여러 특성을 하나로 합치는 것 -> **특성 추출 (feature extraction)**
    - Tip ) 
      - 머신러닝 알고리즘에 데이터를 주입하기 전에 **차원 축소 알고리즘**을 사용하여 훈련 데이터의 차원을 줄이는 것이 유용할 때가 많음
        - 실행 속도가 훨씬 빨라짐
        - 디스크와 메모리를 차지하는 공간 줄어듦
        - 경우에 따라 성능이 좋아지기도 함 

  ![](../../images/t-SNE_visualization.png)

  <div align="center">
      [ 의미 있는 군집을 강조한 t-SNE 시각화 예시 ]
  </div>

  <br>

- `이상치 탐지 (outlier detection)`

  - 학습 알고리즘에 주입하기 전에 데이터셋에서 **이상한 값**을 자동으로 **제거**하는 것

    - 시스템은 훈련하는 동안 대부분 정상 샘플을 만나 이를 인식하도록 훈련 됨
    - 그다음 새로운 샘플을 보고 정상 데이터인지 or 이상치인지 판단

    ![](../../images/anomaly-detection.png)

    <div align="center"> [ 이상치 탐지 ] </div>

<br>

- `특이치 탐지 (novelty detection)`

  - 훈련 세트에 있는 모든 샘플과 **달라 보이는 새로운 샘플**을 탐지하는 것이 목적
  - 알고리즘으로 감지하고 싶은 모든 샘플을 제거한 후 매우 '깨끗한' 훈련 세트가 필요
  - ex)
    - 강아지 사진 수천장 중 1%가 치와와 사진이면 특이치 탐지 알고리즘은 구분 못함
    - but, 이상치 탐지 알고리즘은 치와와 사진을 매우 드물고 다르 강아지와 다르다고 인식

  <br>

- `연관 규칙 학습 (association rule learing)`
  
  - 대량의 데이터에서 특성 간의 흥미로운 관계를 찾는 것

<br>

<br>

#### 준지도 학습 (Semisupervised Learning)

- Data에 label을 다는 것은 일반적으로 시간과 비용이 많이 들기 때문에 label이 없는 sample이 많고 label 된 sample은 적은 경우가 많음

  - 어떤 알고리즘은 **일부만 label이 있는 data**를 다룸

    -> **준지도 학습**

- ex) 

  - 구글 포토 호스팅 서비스

    - 가족 사진을 올리면 사람 A는 1, 5, 11에 있고,  사람 B는 사진 2, 5, 7에 있다고 자동으로 인식

      -> **군집**

    - 사람마다 label을 추가하면 사진에 있는 모든 사람의 이름을 알 수 있고 편리하게 사진을 찾을 수 있음!

- 대부분의 준지도 학습은 지도 학습과 비지도 학습의 조합으로 이루어져 있음

   ![](../../images/semisupervised-learning.png)

<div align="center"> [ 두 개의 class를 사용한 준 지도 학습: 새로운 샘플(곱셈 기호)이 label이 있는 사각형 클래스에 더 가깝지만  label이 없는 샘플(원)이 이 샘플을 삼각형 클래스로 분류하는데 도움을 줌 ] </div>

<br>

<br>

#### 강화 학습 (Reinforcement Learning)

- 시스템을 **에이전트** 라고 부르며 환경을 관찰해서 행동을 실행하고 그 결과로 **보상 (reward)** 또는 **벌점 (penalty)**을 받음

- 시간이 지나면서 가장 큰 보상을 얻기 위해 **정책(policy)**이라고 부르는 최상의 전략을 스스로 학습함

  - 정책은 주어진 상황에서 에이전트가 어떤 행동을 선택해야 할지 정의함

   ![](../../images/reinforcement-learning.png)

<br>

<br>

### 1.4.2 배치 학습과 온라인 학습

> 입력 데이터의 스트림(stream)부터 점진적으로 학습할 수 있는지 여부

<br>

#### 배치 학습 (batch learning)

- 시스템이 점진적으로 학습할 수 없음
- 시간과 자원을 많이 많이 소모함
- 먼저 시스템을 훈련 시키고, 제품 시스템에 적용하면 더 이상의 학습 없이 실행됨
  - 학습한 것을 적용만 함
  - `오프라인 학습(Offline learning)`
- 새로운 데이터에 대해 학습하려면 전체 데이터를 사용하여 새로운 버전을 처음부터 다시 훈련해야 함
  - 간단하고 잘 동작하지만 시간이 오래 소요될 수 있음
    - 빠르게 변하는 데이터에 적응해야 한다면 (ex. 주식가격) 더 능동적인 방법 필요
  - 전체 데이터 셋을 사용해 훈련한다면 많은 컴퓨팅 자원 필요
    - 큰 비용 발생

<br>

#### 온라인 학습 (online learning)

- 데이터를 순차적으로 한 개 씩 or **`미니 배치(mini-batch)`** 라고 부루는 작은 묶음 단위로 주입하여 시스템을 훈련
- 매 학습 단계가 빠르고 비용이 적게 듦
  - 시스템은 데이터가 도착하는 대로 즉시 학습 할 수 있음

![](../../images/online-learning.png)

<div align="center"> [ Online learning ] </div>

- 연속적으로 데이터를 받고 (ex. 주식가격) 빠르 변화에 스스로 적응해야 하는 시스템에 적합

- 컴퓨팅 자원이 제한적일 때에도 좋음

  - why?

    - 온라인 학습 시스템이 새로운 데이터 샘플을 학습하면 학습이 끝난 데이터는 더이상 필요하지 않으므로 버리면 됨
      - 많은 공간 절약 가능!

    <br>

- **`외부 메모리 학습`**

  - 컴퓨터 한 대의 메인 메모리에 들어갈 수 없는 아주 큰 데이터 셋을 학습하는 것
    - 알고리즘이 데이터 일부를 읽어 들이고 훈련
    - 전체 데이터가 모두 적용될 때 까지 이 과정을 반복
  - 보통 offline으로 실행됨
    - 실시간 시스템에서 수행되는 것이 아님
    - 점진적 학습임

  ![](../../images/out-of-core_learning.png)

<div align="center"> [ Online learning을 활용하여 대량의 데이터를 처리하기 ]</div>

<br>

<br>

### 1.4.3 사례 기반 학습과 모델 기반 학습

> 어떻게 일반화 (좋은 예측을 만들어 내는지) 에 따르 분류

<br>

#### 사례 기반 학습 (Instance-based learning)

- 단순히 기억하는 것 (ex. spam filter)
  - 시스템이 훈련 샘플을 기억함으로써 학습함
  - 그리고 **유사도 측정** 을 사용해 새로운 데이터와 학습한 샘플을 비교하는 식으로 일반화

<br>

#### 모델 기반 학습 (Model based learning)

- 샘플들의 모델을 만들어 **예측**에 사용하는 것
- ex) 간단한 선형 모델 
  - 삶의 만족도 = θ0 + θ1 X (1인당GDP)
- **`모델 파라미터 (model parameter)`** 
  - **Theta** (**θ**) 를 활용하여 주로 표현함
    - **Omeaga (Ω)**
    - **Beta (ß)** 

- 모델을 사용하기 전에 `θ0`  과 `θ1` 를 정의해야 함

  - 최상의 값을 내도록 하는 값을 알기 위해 **`측정 지표`** 정하기 

    - 효용함수
      - 모델이 얼마나 좋은지 츨정
    - 비용 함수
      - 모델이 얼마나 나쁜지 측정

  - **`선형회귀`**에서는보통 선형 모델의 예측과 훈련 데이터 사이의 거리를 재는 **비용 함수**를 사용

    - 이 거리를 최소화 하는 것이 목표!

    - **회귀**

      : 연속적인 타깃을 예측하는 알고리즘

<br>

> **예제 1-1** Scikit-Learn을 이용한 선형 모델의 훈련과 실행

```python 
# 예제 코드
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import sklearn.linear_model

# 데이터 적재
oecd_bli = pd.read_csv(datapath + "oecd_bli_2015.csv", thousands=',')
              # [ pandas.read_csv ]
              # : Read a comma-separated values (csv) file into DataFrame.
gdp_per_capita = pd.read_csv(datapath + "gdp_per_capita.csv",thousands=',',delimiter='\t',
                             encoding='latin1', na_values="n/a")

# 데이터 준비
country_stats = prepare_country_stats(oecd_bli, gdp_per_capita)
X = np.c_[country_stats["GDP per capita"]]
y = np.c_[country_stats["Life satisfaction"]]
    # [ numpy.c_ ]
    # : Translates slice objects to concatenation along the second axis.

# 데이터 시각화
country_stats.plot(kind='scatter', x="GDP per capita", y='Life satisfaction')
        # plt.plot()은 라인 플롯을 그리는 함수
plt.show()

# 선형 모델 선택
model = sklearn.linear_model.LinearRegression()
        # 사이킷런의 LinearRegression 클래스는 사이파이SciPy의 lstsq() 함수를 사용하여 선형 회귀 문제를 품
        # -> 특잇값 분해(SVD) 방식을 사용하여 유사 역행렬을 계산

"""
선형 회귀 모델을 K-최근접 이웃 (K-nearest neightbors) 회귀로 바꾸기
"""
# import sklearn.neighbors
# model = sklearn.neighbors.KNeighborsRegressor(n_neighbors=3)

# 모델 훈련
model.fit(X, y)

# 키프로스에 대한 예측
X_new = [[22587]]  # 키프로스 1인당 GDP
print(model.predict(X_new)) # 출력 [[ 5.96242338]]
```

<br>

#### 지금까지의 작업 요약

1. 데이터를 **분석**
2. `모델`을 **선택**
3. `훈련 데이터`로 모델을 **훈련**
4. 새로운 데이터에 모델을 **적용**해 **예측**을 하고 (`추론`), 이 모델이 잘 **일반화** 되기를 기대함 

<br>

<br>

## 1.5 머신러닝의 주요 도전 과제

> 학습 알고리즘을 선택해서 데이터에 훈련시키는 과정에서 문제가 될 수 있는 두 가지
>
> 1. 나쁜 알고리즘
> 2. 나쁜 데이터

<br>

### 1.5.1 충분하지 않은 양의 훈련 데이터

- 대부분의 머신러닝 알고리즘이 잘 작동하려면 데이터가 많아야 함
  - 아주 간단한 문제에서조차도 수천개의 데이터가 필요하고, 이미자 음성 인식 같은 복잡한 문제라면 수백만개가 필요할지도 모름
- 