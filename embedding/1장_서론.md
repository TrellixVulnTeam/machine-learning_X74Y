# 1장 - 서론

> Reference: [책] 한국어 임베딩

<br>
<br>

## 새로 알게 된 내용

- `임베딩이란?`
  - 사람이 쓰는 자연어를 기계가 이해할 수 있는 숫자의 나열인 벡터(vector)로 바꾼 결과 혹은 그 일련의 과정
  - 단어나 문장을 각각 벡터로 변환해 벡터 공간(vector space)으로 끼워 넣는다(embed)는 의미에서 임베딩이라는 이름이 붙었다
- `코사인 유사도(cosine similarity)`
  - 각 쿼리 단어 별 벡터 간 유사도 측정 기법의 일종
- `단어 유추 평가(word analogy test)`
  - 단어 임베딩을 평가하는 방법
- `전이 학습(transfer learning)`
  - 임베딩을 다른 딥러닝 모델의 입력값으로 쓰는 기법
- `잠재 의미 분석(Latent Semantic Analysis)`
  - 단어 사용 빈도 등 말뭉치의 통계랑 정보가 들어 있는 커다란 행렬(matrix)에 특이값 분해(singular value decomposition) 등 수학적 기법을 적용해서, 행렬에 속한 벡터들의 차원을 축소하는 방법
- `희소 행렬(sparse matrix)`
  - 대부분의 요소 값이 0인 행렬
  - 희소 행렬을 다른 모델의 입력값으로 쓰게 되면, 계산량과 메모리가 커지므로 행렬의 차원을 축소해 사용한다
- `뉴럴 네트워크 (Neural Network) 기반 임베딩`
  - Neural Network 기반 model들은
    1. 이전 단어들이 주어졌을 때, 다음 단어가 뭐가 될지 예측하거나
    2. 문장 내 일부분에 구멍을 뚫어 놓고(masking), 해당 단어가 무엇일지 맞추는 과정에서 학습된다
- `단어 수준 임베딩과 문장 수준 임베딩`
  - 단어 수준 임베딩 기법의 단점은 동음이의어(homonym)를 분간하기 어렵다는 점이다
  - 문장 수준 임베딩 기법은 개별 단어가 아닌 단어 시퀀스 (sequence) 전체의 문맥적 의미를 함추하기 때문에 단어 임베딩 기법보다 전이 학습 효과가 좋다
- `피쳐 (Feature)`
  - 모델의 입력값을 가리킨다
- `엔드투엔드 모델 (End-to-end model)`
  - 데이터를 통째로 model에 넣고, 입출력 사이의 관계를 사람의 개입 없이 model 스스로 처음부터 끝까지 이해하도록 유도하는 기법
- `Pretrain과 Fine Tuning`
  - 대규모 말뭉치로 임베딩을 만든다 (**pretrain**)
    - 이 임베딩에는 말뭉치의 의미적, 문법적 맥락이 포함되어 있다
  - 임베딩을 입력으로 하는 새로운 딥러닝 모델을 만들고, 풀고싶은 구체적 문제에 맞는 소규모 데이터에 맞게 임베딩을 포함한 model 전체를 update한다 (**Fine Tuning**, **전이 학습**)
- `Downstream task와 Upstream task`
  - Downstream task
    - 풀고 싶은 자연어 처리의 구체적 문제
  - Upstream task
    - Downstream task에 앞서 해결해야 할 과제
- `임베딩의 종류`
  - **행렬 분해(factorization) 기반 방법**
    - 말뭉치 정보가 들어 있는 원래 행렬을 두 개 이상의 작은 행렬로 쪼개는 방식의 임베딩 기법
  - **예측 기반 방법**
    1. 어떤 단어 주변에 특정 단어가 나타날지 예측하거나,
    2. 이전 단어들이 주여 졌을 때 다음 단어가 무엇일지 예측하거나,
    3. 문장 내 일부 단어를 지우고 해당 단어가 무엇일지 맞추는 과정에서 학습하는 방법
  - **토픽 기반 방법**
    - 주어진 문서에 잠재된 주제(latent topic)를 추론(inference)하는 방식으로 임베딩 기법
    - 잠재 디리클레 할당(Latent Dirichlet Allocation)이 대표적인 기법이다
      - 학습이 완료되면 각 문서가 어떤 주제 분포(topic distribution)를 갖는지 확률 벡터 형태로 반환한다
- `말뭉치 (corpus)`
  - 임베딩 학습이라는 특정한 목적을 가지고 수집한 표본(sample)
- `컬렉션 (collection)`
  - 말뭉치에 속한 각각의 집합
- `토큰 (token)`
  - 이 책에서 다루는 가장 작은 단위
- `토크나이즈 (tokenize)`
  - 문장을 token sequence로 분석하는 과정
- `형태소 분석 (morphological analysis)`
  - 문장을 형태소 sequence로 나누는 과정
- `어휘 집합 (vocabulary)`
  - 말뭉치(corpus)에 있는 모든 문서를 문장으로 나누고, 여기에 tokenize를 실시한 후 중복을 제거한 token들의 집합
- `미등록 단어 (unknown word)`
  - 어휘 집합에 없는 token 

