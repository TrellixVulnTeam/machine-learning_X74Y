# 1장 - 서론

> Reference: [책] 한국어 임베딩

<br>
<br>

## 새로 알게 된 내용

- `임베딩이란?`
  - 사람이 쓰는 자연어를 기계가 이해할 수 있는 숫자의 나열인 벡터(vector)로 바꾼 결과 혹은 그 일련의 과정
  - 단어나 문장을 각각 벡터로 변환해 벡터 공간(vector space)으로 끼워 넣는다(embed)는 의미에서 임베딩이라는 이름이 붙었다
- `코사인 유사도(cosine similarity)`
  - 각 쿼리 단어 별 벡터 간 유사도 측정 기법의 일종
- `단어 유추 평가(word analogy test)`
  - 단어 임베딩을 평가하는 방법
- `전이 학습(transfer learning)`
  - 임베딩을 다른 딥러닝 모델의 입력값으로 쓰는 기법
- `잠재 의미 분석(Latent Semantic Analysis)`
  - 단어 사용 빈도 등 말뭉치의 통계랑 정보가 들어 있는 커다란 행렬(matrix)에 특이값 분해(singular value decomposition) 등 수학적 기법을 적용해서, 행렬에 속한 벡터들의 차원을 축소하는 방법
- `희소 행렬(sparse matrix)`
  - 대부분의 요소 값이 0인 행렬
  - 희소 행렬을 다른 모델의 입력값으로 쓰게 되면, 계산량과 메모리가 커지므로 행렬의 차원을 축소해 사용한다
- `뉴럴 네트워크 (Neural Network) 기반 임베딩`
  - Neural Network 기반 model들은
    1. 이전 단어들이 주어졌을 때, 다음 단어가 뭐가 될지 예측하거나
    2. 문장 내 일부분에 구멍을 뚫어 놓고(masking), 해당 단어가 무엇일지 맞추는 과정에서 학습된다
- `단어 수준 임베딩과 문장 수준 임베딩`
  - 단어 수준 임베딩 기법의 단점은 동음이의어(homonym)를 분간하기 어렵다는 점이다
  - 문장 수준 임베딩 기법은 개별 단어가 아닌 단어 시퀀스 (sequence) 전체의 문맥적 의미를 함추하기 때문에 단어 임베딩 기법보다 전이 학습 효과가 좋다
- `피쳐 (Feature)`
  - 모델의 입력값을 가리킨다
- `엔드투엔드 모델 (End-to-end model)`
  - 데이터를 통째로 model에 넣고, 입출력 사이의 관계를 사람의 개입 없이 model 스스로 처음부터 끝까지 이해하도록 유도하는 기법

